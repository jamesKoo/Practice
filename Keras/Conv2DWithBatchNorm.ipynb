{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2DWithBatchNorm\n",
    "### custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2DWithBatchNorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Conv2DWitBatchNorm(Conv2D):\n",
    "    def __init__(self,  filters, kernel_size, padding='valid', **kwargs):\n",
    "        super().__init__(filters=filters, kernel_size=kernel_size, padding=padding, use_bias=False, **kwargs)\n",
    "    def call(self, x):\n",
    "        conv = super().call(x)\n",
    "        batchNorm = BatchNormalization()(conv)\n",
    "        act = Activation('relu')(batchNorm)\n",
    "        return act\n",
    "    \n",
    "def Conv2DWithBatchNorm_f(in_layer, filters, kernel_size, activation='relu',\n",
    "                        padding='same', bias=False, name=None):\n",
    "    conv = Conv2D(filters, kernel_size, padding=padding, use_bias=bias, name=name)(in_layer)\n",
    "    batch_norm = BatchNormalization()(conv)\n",
    "    act = Activation(activation)(batch_norm)\n",
    "\n",
    "    return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Code\n",
    "Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2000, 32, 32, 3)\n",
      "2000 train samples\n",
      "200 test samples\n",
      "y_train: (2000, 10)\n",
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 21s - loss: 2.2803 - acc: 0.1330 - val_loss: 2.1579 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 17s - loss: 2.1311 - acc: 0.2295 - val_loss: 2.1118 - val_acc: 0.2450\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 16s - loss: 1.9605 - acc: 0.2835 - val_loss: 2.1866 - val_acc: 0.2050\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 16s - loss: 1.8794 - acc: 0.3250 - val_loss: 1.8931 - val_acc: 0.3500\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 16s - loss: 1.7762 - acc: 0.3485 - val_loss: 1.7728 - val_acc: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183d29264a8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train[:2000]\n",
    "y_train = y_train[:2000]\n",
    "x_test = x_test[:200]\n",
    "y_test = y_test[:200]\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train:', y_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2DWithBatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2000, 32, 32, 3)\n",
      "2000 train samples\n",
      "200 test samples\n",
      "y_train: (2000, 10)\n",
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 37s - loss: 2.3200 - acc: 0.2625 - val_loss: 2.3772 - val_acc: 0.1050\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 32s - loss: 1.8340 - acc: 0.3765 - val_loss: 2.6154 - val_acc: 0.1400\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 35s - loss: 1.5673 - acc: 0.4520 - val_loss: 3.1148 - val_acc: 0.1100\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 37s - loss: 1.4275 - acc: 0.4905 - val_loss: 3.4719 - val_acc: 0.0850\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 36s - loss: 1.2575 - acc: 0.5560 - val_loss: 3.5891 - val_acc: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183a378f9b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train[:2000]\n",
    "y_train = y_train[:2000]\n",
    "x_test = x_test[:200]\n",
    "y_test = y_test[:200]\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train:', y_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2DWitBatchNorm(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2DWitBatchNorm(32, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2DWitBatchNorm(64, (3, 3), padding='same'))\n",
    "model.add(Conv2DWitBatchNorm(64, (3, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2000, 32, 32, 3)\n",
      "2000 train samples\n",
      "200 test samples\n",
      "y_train: (2000, 10)\n",
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 36s - loss: 2.3067 - acc: 0.2785 - val_loss: 2.3162 - val_acc: 0.1750\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 34s - loss: 1.7719 - acc: 0.4010 - val_loss: 2.5454 - val_acc: 0.1150\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 36s - loss: 1.5522 - acc: 0.4610 - val_loss: 3.2055 - val_acc: 0.1050\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 33s - loss: 1.3823 - acc: 0.5185 - val_loss: 3.4742 - val_acc: 0.1050\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 35s - loss: 1.2088 - acc: 0.5775 - val_loss: 4.2073 - val_acc: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183d3431748>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train[:2000]\n",
    "y_train = y_train[:2000]\n",
    "x_test = x_test[:200]\n",
    "y_test = y_test[:200]\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train:', y_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
